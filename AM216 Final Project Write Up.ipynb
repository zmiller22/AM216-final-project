{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AM216 Final Project\n",
    "## Zachary Miller\n",
    "\n",
    "### Abstract\n",
    "Neuron classification based on morphology is an extremely important task in neuroinformatics. Such classifications can allow insight into data collected using methods that traditionally preclude the information that the classifier is meant to estimate. For example, neurons collected using electron microscopy give incredibly detailed morphological inofrmation about the neuron, but lack information regarding neurotransmitter type or functional activity. Classifiers could be able to learn subtle reltionships between morphology and these other features, and thus fill in the missing information after the fact. Here, I investiage the potential of graph neural networks for classifying neurons encoded as attributed graphs.\n",
    "\n",
    "### Project Motivation\n",
    "The goal of this project was to investigate the efficacy of representing neuron morphologies as attributed graphs for classification tasks. The standard format for working with neuron morphologies in the .swc format, which stores neurons as a set of spatial data (\"nodes\") attached by a series of edges. Though very convenient for visualization and qualitative tasks, these file formats are difficult to work with for classification tasks since there are currently no classification models that can work directly with .swc files. The traditional approach for dealing with this problem has been to pick several features of interest and extract these into a feature vector for each neuron and perform classificaiton on these feature vectors alone. However, this approach has seen limited success for classification tasks in the past and has several drawbacks. Most notably, this approach requires a human to hand pick features that might be of interest for the classification task at hand. Such features are rarely known a priori and will change depending on the specifics of the classification task at hand. Furthermore, the features that would lead to the best classification results will not necessarily come in a form that is intuitive for humans, and therefore may never even be considered for the feature vectors. Therefore, it is of great interest to find a more native data representation for neuron morphologies that would allow a model to learn from the data directly.\n",
    "\n",
    "One such representation could be an attributed graph (AG). That is, a graph where each node in the network has a vector of associated data, called an \"attribute\". In fact, the .swc file format is already essientially an AG, so conversion from a .swc file to an AG is very easy. Combined with recent advances in graph neural networks (GNN), attributed graphs may offer a far better way of encoding neural morphology data for classification tasks, especially when there is a lot of data available for training the GNN. This project began investigating the ability of GNNs to classify neuron morphologies based on AG representations.\n",
    "\n",
    "### Data and Methods\n",
    "For this project, I started a data set containing 3,119 unlabeled, spatially registered .swc files representing neurons in the larval zebrafish. These neurons were then labeled into 10 different classes and converted into AGs using the natverse suite of R libraries for dealing with neuron morphologies in the accompanying R script. The labels were generated using the NBLAST algortithm and heirarchical clustering implimented in `nat.nblast`. This algorithm has been used with great success to cluster neurons into different cell types in numerous previous studies, and I am considering the 10 clusters identified with NBLAST to be ground truth. It is worth noting, however, that the choice of these 10 clusters does not map onto any morphologically meaningful division of these cells (though cells within labels are more \"similar\" than cells acoross labels), this project was simply an exploritory analysis to see if the GCN could learn to classify cells with non-arbitrary labels. These resluting graphs and their labels were then read into python, where I added a self edge to each node and transformed into the format accepted by `DeepGraphLibrary` (more on that in a second). Performing this preprocessing below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import networkx as nx \n",
    "import tensorflow as tf\n",
    "import dgl\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from classifier import GCN\n",
    "\n",
    "#  Set paths to data and labels\n",
    "data_path = \"/home/zack/Desktop/Lab_Work/Data/neuron_morphologies/Zebrafish/aligned_040120/Zbrain_neurons_graphs\"\n",
    "lbl_path = \"/home/zack/Desktop/Lab_Work/Data/neuron_morphologies/Zebrafish/aligned_040120/test_NBLAST_labels.csv\"\n",
    "\n",
    "# Read in the data\n",
    "graph_list = []\n",
    "lbl_list = []\n",
    "name_list = []\n",
    "\n",
    "# Read in the labels and remove the file extension from the names\n",
    "lbls_df = pd.read_csv(lbl_path, index_col=0)\n",
    "lbls_df.index = list(map(lambda x : os.path.splitext(x)[0], lbls_df.index))\n",
    "\n",
    "# \n",
    "dir_obj = os.fsencode(data_path)\n",
    "for file in os.listdir(dir_obj):\n",
    "    filename = os.fsdecode(file)\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    \n",
    "    if os.path.isdir(file_path) == False:\n",
    "        # Load the graph as an nx_graph and get the node attributes for\n",
    "        # conversion into a DGL graph\n",
    "        nx_graph = nx.read_gml(file_path)\n",
    "        nx_atbs = list(nx_graph.nodes.data())\n",
    "        num_nodes = len(nx_atbs)\n",
    "        node_atbs = np.zeros((num_nodes, 4))\n",
    "        \n",
    "        # Aggregate all the node attributes into one numpy array\n",
    "        for idx, node in enumerate(nx_atbs):\n",
    "            node_atbs[idx, 0] = node[1]['X']\n",
    "            node_atbs[idx, 1] = node[1]['Y']\n",
    "            node_atbs[idx, 2] = node[1]['Z']\n",
    "            node_atbs[idx, 3] = node[1]['diam']\n",
    "            \n",
    "        # Add \"self\" edges so each node will be included in its own convolution\n",
    "        nx_graph.add_edges_from(zip(nx_graph.nodes(), nx_graph.nodes()))\n",
    "        \n",
    "        # Create the DGL graph with the node attributes\n",
    "        dgl_graph = dgl.DGLGraph()\n",
    "        dgl_graph.from_networkx(nx_graph)\n",
    "        dgl_graph.ndata['data'] = tf.convert_to_tensor(node_atbs, \n",
    "                                                       dtype=tf.float32)\n",
    "        \n",
    "        # Add all the elements to lists\n",
    "        graph_list.append(dgl_graph)\n",
    "        lbl_list.append(lbls_df.loc[filename,\"nblast_cluster\"])\n",
    "        name_list.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual classification of the cells, I chose to use a graph convolutional neural network (GCN) implimented with `DeepNetworkLibrary` (dgl) and `TensorFlow` (tf). I chose to use the GCN because of its simplicity and track record in graph classification, particulaly with molecules encodded as graphs. The idea behind a GCN is similar to the of a traditional convolutional neural network for image classification. However, rather than convolving some function over groups of nearby pixels in an image, the GCN convolves over the features of \"nearby\" nodes in the network. Repeating this operation many times in series can allow the network to learn very detailed combinations of local features that map onto the classes it is trying to learn. If we denote a graph as $G$, then mathematically a single graph convolutional layer is trying to learn a function such that $h^{l+1}=f(h^l,G)$, where $h^l$ is the convolved node attribute vector for node $l$. There are many different ways to formulate $f(\\cdot)$ such that it can be tuned by the GCN. I chose to use dgl's base implimentation of $f(\\cdot)$, which leads to the function $h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h_j^{(l)}W^{(l)})$. Here, $\\mathcal{N}(i)$ is the neighborhood set of node $i$, $c_{ij}$ is a normalization constant given by $c_{ij} = \\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}$, $\\sigma$ is an activation function, $b^l$ is a learnable bias, and $W^{(l)}$ is a learnable weight matrix. When a graph is put through a layer, this function is iterated over the $h^l$ of every node in the graph in order to form the updated $h^{l+1}$. Notice that this means that $N$ consecutive convolution layers allows information to be considered from $N^{th}$ order neighbors of any given node. \n",
    "\n",
    "For my network, I used 3 consecutive graph convolution layers as described above. For my activation function, I used a leaky RELU activation (tradional RELU was leading to many \"dead\" neurons). These layers were followed by an averaging of the final $h$ node attribute accross all nodes in the graph. The resulting vector was then fed into a single dense layer made up of 10 nodes (one for each class). That network architecture is implimented in `classifier.py`. I then created a 70/15/15 train/validate/test split and trained the network using backpropogation with categorical crossentropy as my loss. Looking at the results below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0, total training loss 9919.8867\n",
      "Calculating validation loss...\n",
      "Epoch 0, total validation loss 906.4484\n",
      "Epoch 1, total training loss 4162.9302\n",
      "Calculating validation loss...\n",
      "Epoch 1, total validation loss 794.7467\n",
      "Epoch 2, total training loss 3265.9395\n",
      "Calculating validation loss...\n",
      "Epoch 2, total validation loss 765.2902\n",
      "Epoch 3, total training loss 2913.6863\n",
      "Calculating validation loss...\n",
      "Epoch 3, total validation loss 677.8873\n",
      "Epoch 4, total training loss 2729.7449\n",
      "Calculating validation loss...\n",
      "Epoch 4, total validation loss 535.4236\n",
      "Epoch 5, total training loss 2586.6021\n",
      "Calculating validation loss...\n",
      "Epoch 5, total validation loss 510.5650\n",
      "Epoch 6, total training loss 2477.9734\n",
      "Calculating validation loss...\n",
      "Epoch 6, total validation loss 488.9573\n",
      "Epoch 7, total training loss 2400.1892\n",
      "Calculating validation loss...\n",
      "Epoch 7, total validation loss 489.0369\n",
      "Epoch 8, total training loss 2336.7012\n",
      "Calculating validation loss...\n",
      "Epoch 8, total validation loss 482.8264\n",
      "Epoch 9, total training loss 2285.4131\n",
      "Calculating validation loss...\n",
      "Epoch 9, total validation loss 476.4442\n",
      "Epoch 10, total training loss 2241.3960\n",
      "Calculating validation loss...\n",
      "Epoch 10, total validation loss 480.9593\n",
      "Epoch 11, total training loss 2193.5317\n",
      "Calculating validation loss...\n",
      "Epoch 11, total validation loss 469.2794\n",
      "Epoch 12, total training loss 2144.9697\n",
      "Calculating validation loss...\n",
      "Epoch 12, total validation loss 464.6946\n",
      "Epoch 13, total training loss 2099.8967\n",
      "Calculating validation loss...\n",
      "Epoch 13, total validation loss 464.2725\n",
      "Epoch 14, total training loss 2069.0784\n",
      "Calculating validation loss...\n",
      "Epoch 14, total validation loss 460.6650\n",
      "Epoch 15, total training loss 2036.3165\n",
      "Calculating validation loss...\n",
      "Epoch 15, total validation loss 457.3838\n",
      "Epoch 16, total training loss 2011.0964\n",
      "Calculating validation loss...\n",
      "Epoch 16, total validation loss 451.7429\n",
      "Epoch 17, total training loss 1988.4980\n",
      "Calculating validation loss...\n",
      "Epoch 17, total validation loss 450.5242\n",
      "Epoch 18, total training loss 1960.1608\n",
      "Calculating validation loss...\n",
      "Epoch 18, total validation loss 445.9918\n",
      "Epoch 19, total training loss 1939.9205\n",
      "Calculating validation loss...\n",
      "Epoch 19, total validation loss 443.9163\n",
      "Test loss was 394.4987 for 72.92 percent accuracy\n"
     ]
    }
   ],
   "source": [
    "# Format the data for training\n",
    "lbl_arr = np.asarray(lbl_list)[:,np.newaxis]\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "lbl_arr = enc.fit_transform(lbl_arr)\n",
    "\n",
    "combined_list = list(zip(name_list, graph_list, lbl_arr))\n",
    "random.shuffle(combined_list)\n",
    "split_1 = int(0.7*len(combined_list))\n",
    "split_2 = int(0.15*len(combined_list))\n",
    "train_data = combined_list[:split_1]\n",
    "val_data = combined_list[split_1:split_1+split_2]\n",
    "test_data = combined_list[split_1+split_2:]\n",
    "\n",
    "# Train the model\n",
    "model = GCN(4, 32, 10)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "EPOCHS = 20\n",
    "PATIENCE = 2\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "print(\"Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss = 0\n",
    "    for (name, graph, lbl) in train_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            lbl = lbl.reshape(1,10)\n",
    "            prediction = model(graph)\n",
    "            loss = loss_func(lbl, prediction)\n",
    "            grads = tape.gradient(loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            epoch_train_loss += loss\n",
    "            \n",
    "    print('Epoch {}, total training loss {:.4f}'.format(epoch, epoch_train_loss))\n",
    "    print(\"Calculating validation loss...\")\n",
    "    for (name, graph, lbl) in val_data:\n",
    "        lbl = lbl.reshape(1,10)\n",
    "        prediction = model(graph)\n",
    "        loss = loss_func(lbl, prediction)\n",
    "        epoch_val_loss += loss\n",
    "    \n",
    "    print('Epoch {}, total validation loss {:.4f}'.format(epoch, epoch_val_loss))\n",
    "    val_loss_list.append(epoch_val_loss)\n",
    "    if epoch >= PATIENCE:\n",
    "        if max(val_loss_list[epoch-PATIENCE:])<epoch_val_loss:\n",
    "            print('Training stopped on epoch {}'.format(epoch))\n",
    "            break\n",
    "    \n",
    "    # Can't use standard ways of saving a tf model since this is a custom model.\n",
    "    # Normally this means you have to set the input shape manually and then you\n",
    "    # can save, but in this case the input shape is variable. I will have to figure\n",
    "    # this out in the future...\n",
    "    \n",
    "    # model_path = '/home/zack/Documents/AM216/final_project/best_model/1/'\n",
    "    # tf.saved_model.save(model, model_path)\n",
    "    \n",
    "# Test the model\n",
    "true_lbls = np.asarray([element[2] for element in test_data])\n",
    "model_predictions = np.zeros((len(test_data),10))\n",
    "\n",
    "test_loss = 0\n",
    "for i, (name, graph, lbl) in enumerate(test_data):\n",
    "    lbl = lbl.reshape(1,10)\n",
    "    prediction = model(graph)\n",
    "    loss = loss_func(lbl, prediction)\n",
    "    test_loss += loss\n",
    "    model_predictions[i,np.argmax(prediction)] = 1\n",
    "    \n",
    "results = true_lbls+model_predictions\n",
    "num_correct = results[results==2].shape[0]\n",
    "total_num = len(test_data)\n",
    "acc = num_correct/total_num\n",
    "\n",
    "print(\"Test loss was {:.4f} for {:.2f} percent accuracy\".format(test_loss, 100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Discussion\n",
    "72.92 percent accuracy across 10 classes is extremely promising given the simplicity of the model outlined above, especially when considering the accuracy of previous cell type classification results which tend to hover around the 75-90% range. Two things in particular could be greatly improved upon in future. First, the network architecture could be much more sophisticated. This includes adding more layers to model in order to consider higher order neighbors for each node, using more sophisticated convolution functions, and adding more dense layers to the network. Second, the step of averaging all the $h$ nodes of the graph in order to get a single fixed length vector representation of the graph could be made more complex to allow for richer representations of the graph, though this step must remain differentiable in order to allow for training using backpropogation. Together, these adjustments could greatly improve upon the accuracy of the simple model used here.\n",
    "\n",
    "One point of skepticism that I have, however, is regarding the difficulty of the classification task at hand. Clustering using NBLAST is known to heavily weight the spatial location of the neurons compared to some more local geometric features. Therefore, when clustering 3,119 neurons spanning the entire brain of the larval zebrafish, it is possible that NBLAST simply divided the neurons into 10 groups based on their soma location, or some other purely spatial feature. It could be the case that the convolutional layers of the above GCN are really doing nothing more calculating the an approximate average of the node features, 3 of 4 of which are the spatial coordinates of the node, and then the dense layer is doing all the heavy lifting for classification. If that is the case, then the above GCN might generalize well to neuron classification tasks that are spatially seperable but do terribly when expected to learn classification paradigms that are spatially similar but geometrically differentiated. In order to test whether a GCN can adapt to the latter situation, it should be trained and tested on a dataset for which the neurons are all in the same region of the brain and are differentiable only by branching patterns or other more geometric features. It is worth noting, however, that the classifier above was trained and tested previously with only a single convolutional layer and showed far worse accuracy, which may be an indication that the convolutional layers are doing something useful beyond simply averaging the spatial location of the nodes.\n",
    "\n",
    "### Conclusion\n",
    "The results obtained above are promising, especially within the context of neuron classification tasks. However, these results were obained using data with synthetic labels and it is unclear how well they might generalize to real world classification tasks. Additionally, the method used here may struggle when faced with classification tasks that can only be differentiated geometrically. Still, when considered as preliminary results for the efficacy of GNNs for classification of neuron morphologies represented using AGs, the results here seem to warrant further investigation. One might start by comparing the classification accuracy for this dataset with the synthetic labels using more traditional classification methods to the method used here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
